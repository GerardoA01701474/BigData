{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad Big Data\n",
        "### Gerardo Peña Pérez\n",
        "### A01701474\n"
      ],
      "metadata": {
        "id": "eDOxuE8fngkQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "eiMOIZicYjLb",
        "outputId": "55f5262a-d49d-42e0-8c93-3fe1f490ac7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rIgn:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\u001b[0m\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [W\u001b[0m\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [C\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com (185.125.190.39\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.2.2-bin-hadoop3.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.2-bin-hadoop3.2.tgz  \n",
        "# Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "# Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.2-bin-hadoop3.2\"\n",
        "\n",
        "# Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "yIheD8vFkmQU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la sesión de spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark_session = SparkSession.builder.appName('ActividadBigData').getOrCreate()\n",
        "spark_session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "naDER8trYlhP",
        "outputId": "1a52f4a7-e7a4-46de-ca7e-08d72bf37332"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f52a2c03910>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://be05c2644c87:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ActividadBigData</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el data set que se usará\n",
        "# En este caso elegí un dataset sobre cancer de mama\n",
        "# Intentaré predecir si el tumor es benigno o maligno basandome en distintas características del tumor\n",
        "dataset = spark_session.read.csv('sample_data/breast-cancer-wisconsin (1).csv', header=True, inferSchema=True)\n",
        "dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FYDvwIGaHK7",
        "outputId": "49c3fa57-1bf9-420f-811d-aa513b49cee5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+-----------------------+------------------------+-----------------+---------------------------+-----------+---------------+---------------+-------+-----+\n",
            "|Sample_code_number|Clump_Thickness|Uniformity_of_Cell_Size|Uniformity_of_Cell_Shape|Marginal_Adhesion|Single_Epithelial_Cell_Size|Bare_Nuclei|Bland_Chromatin|Normal_Nucleoli|Mitoses|Class|\n",
            "+------------------+---------------+-----------------------+------------------------+-----------------+---------------------------+-----------+---------------+---------------+-------+-----+\n",
            "|           1000025|              5|                      1|                       1|                1|                          2|          1|              3|              1|      1|    2|\n",
            "|           1002945|              5|                      4|                       4|                5|                          7|         10|              3|              2|      1|    2|\n",
            "|           1015425|              3|                      1|                       1|                1|                          2|          2|              3|              1|      1|    2|\n",
            "|           1016277|              6|                      8|                       8|                1|                          3|          4|              3|              7|      1|    2|\n",
            "|           1017023|              4|                      1|                       1|                3|                          2|          1|              3|              1|      1|    2|\n",
            "|           1017122|              8|                     10|                      10|                8|                          7|         10|              9|              7|      1|    4|\n",
            "|           1018099|              1|                      1|                       1|                1|                          2|         10|              3|              1|      1|    2|\n",
            "|           1018561|              2|                      1|                       2|                1|                          2|          1|              3|              1|      1|    2|\n",
            "|           1033078|              2|                      1|                       1|                1|                          2|          1|              1|              1|      5|    2|\n",
            "|           1033078|              4|                      2|                       1|                1|                          2|          1|              2|              1|      1|    2|\n",
            "|           1035283|              1|                      1|                       1|                1|                          1|          1|              3|              1|      1|    2|\n",
            "|           1036172|              2|                      1|                       1|                1|                          2|          1|              2|              1|      1|    2|\n",
            "|           1041801|              5|                      3|                       3|                3|                          2|          3|              4|              4|      1|    4|\n",
            "|           1043999|              1|                      1|                       1|                1|                          2|          3|              3|              1|      1|    2|\n",
            "|           1044572|              8|                      7|                       5|               10|                          7|          9|              5|              5|      4|    4|\n",
            "|           1047630|              7|                      4|                       6|                4|                          6|          1|              4|              3|      1|    4|\n",
            "|           1048672|              4|                      1|                       1|                1|                          2|          1|              2|              1|      1|    2|\n",
            "|           1049815|              4|                      1|                       1|                1|                          2|          1|              3|              1|      1|    2|\n",
            "|           1050670|             10|                      7|                       7|                6|                          4|         10|              4|              1|      2|    4|\n",
            "|           1050718|              6|                      1|                       1|                1|                          2|          1|              3|              1|      1|    2|\n",
            "+------------------+---------------+-----------------------+------------------------+-----------------+---------------------------+-----------+---------------+---------------+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quiero ver si todos los tipos de datos son correctos\n",
        "dataset.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC4A5ubNcnnt",
        "outputId": "81889c84-f591-4140-f07b-b33d30aac701"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Sample_code_number: integer (nullable = true)\n",
            " |-- Clump_Thickness: integer (nullable = true)\n",
            " |-- Uniformity_of_Cell_Size: integer (nullable = true)\n",
            " |-- Uniformity_of_Cell_Shape: integer (nullable = true)\n",
            " |-- Marginal_Adhesion: integer (nullable = true)\n",
            " |-- Single_Epithelial_Cell_Size: integer (nullable = true)\n",
            " |-- Bare_Nuclei: string (nullable = true)\n",
            " |-- Bland_Chromatin: integer (nullable = true)\n",
            " |-- Normal_Nucleoli: integer (nullable = true)\n",
            " |-- Mitoses: integer (nullable = true)\n",
            " |-- Class: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# El atributo Sample_code_number es solo un identificador, así que lo puedo quitar,al igual que otras columnas innecesarias\n",
        "dataset = dataset.drop(\"Sample_code_number\")\n",
        "dataset = dataset.drop(\"Bare_Nuclei\")"
      ],
      "metadata": {
        "id": "FrqpGWEncvfP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignamos como indice a la columna con el resultado (class=2 -> benigno) (class=4 -> maligno)\n",
        "my_index = StringIndexer(inputCol='Class', outputCol='classNew')\n",
        "fitted = my_index.fit(dataset)\n",
        "new_df = fitted.transform(dataset)\n",
        "new_df = new_df.drop(\"Class\")\n",
        "\n",
        "# dividimos entre datos de entrenamiento y datos de testeo,asignando 70% y 30% respectivamente\n",
        "\n",
        "(data_train, data_test) = new_df.randomSplit([0.7, 0.3], seed=17)"
      ],
      "metadata": {
        "id": "O85NXac2dEEz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"Clump_Thickness\",\n",
        "        \"Uniformity_of_Cell_Size\", \"Uniformity_of_Cell_Shape\", \n",
        "        \"Marginal_Adhesion\", \"Single_Epithelial_Cell_Size\",\n",
        "        #\"Bare_Nuclei\",\n",
        "         \"Bland_Chromatin\", \n",
        "        \"Normal_Nucleoli\", \"Mitoses\"]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=cols,\n",
        "    outputCol=\"features\")\n",
        "\n",
        "transformed_train = assembler.transform(data_train)\n",
        "transformed_test = assembler.transform(data_test)\n",
        "transformed_train = transformed_train.drop(*cols)\n",
        "transformed_test = transformed_test.drop(*cols)\n",
        "transformed_train.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7IHci2qdMOM",
        "outputId": "7f1709ce-c669-4c5a-c792-344ef0304a2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|classNew|            features|\n",
            "+--------+--------------------+\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "|     0.0|[1.0,1.0,1.0,1.0,...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib import linalg as mllib_linalg\n",
        "from pyspark.ml import linalg as ml_linalg\n",
        "\n",
        "def as_old(v):\n",
        "    if isinstance(v, ml_linalg.SparseVector):\n",
        "        return mllib_linalg.SparseVector(v.size, v.indices, v.values)\n",
        "    if isinstance(v, ml_linalg.DenseVector):\n",
        "        return mllib_linalg.DenseVector(v.values)\n",
        "    raise ValueError(\"Unsupported type {0}\".format(type(v)))"
      ],
      "metadata": {
        "id": "sxp1p74lf7wS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "train_dataset = (transformed_train.select(col(\"classNew\").alias(\"label\"), col(\"features\"))\\\n",
        "                  .rdd.map(lambda row: LabeledPoint(row.label, as_old(row.features))))\n",
        "\n",
        "\n",
        "test_dataset = (transformed_test.select(col(\"classNew\").alias(\"label\"), col(\"features\"))\\\n",
        "                  .rdd.map(lambda row: LabeledPoint(row.label, as_old(row.features))))"
      ],
      "metadata": {
        "id": "-d978TI5jXEk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como el problema con el que nos encontramos es de clasificación aplicaremos un decision tree con MLlib de pyspark\n",
        "from pyspark.mllib.tree import DecisionTree\n",
        "from pyspark.mllib.tree import DecisionTreeModel\n",
        "\n",
        "numClasses = 2\n",
        "categoricalFeaturesInfo = {}\n",
        "impurity = \"gini\"\n",
        "\n",
        "# transformamos el dataframe a un rdd y poder usar MLlib\n",
        "model = DecisionTree.trainClassifier(train_dataset, numClasses, \n",
        "                                     categoricalFeaturesInfo, impurity)"
      ],
      "metadata": {
        "id": "ySMUn266jbxN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset.map(lambda x: x.features))\n",
        "labelsAndPredictions = test_dataset.map(lambda lp: lp.label).zip(predictions)\n",
        "testErr = labelsAndPredictions.filter(lambda lp: lp[0] != lp[1]).count() / float(test_dataset.count())\n",
        "print('Test Error = ' + str(testErr))\n",
        "print('Tree model:')\n",
        "print(model.toDebugString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3XxZPW0jkPX",
        "outputId": "fd6c63ae-872f-4dab-f932-925156e88683"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.136986301369863\n",
            "Tree model:\n",
            "DecisionTreeModel classifier of depth 5 with 31 nodes\n",
            "  If (feature 1 <= 2.5)\n",
            "   If (feature 0 <= 6.5)\n",
            "    If (feature 4 <= 5.5)\n",
            "     If (feature 6 <= 3.5)\n",
            "      Predict: 0.0\n",
            "     Else (feature 6 > 3.5)\n",
            "      If (feature 0 <= 4.5)\n",
            "       Predict: 0.0\n",
            "      Else (feature 0 > 4.5)\n",
            "       Predict: 1.0\n",
            "    Else (feature 4 > 5.5)\n",
            "     If (feature 0 <= 3.5)\n",
            "      Predict: 0.0\n",
            "     Else (feature 0 > 3.5)\n",
            "      Predict: 1.0\n",
            "   Else (feature 0 > 6.5)\n",
            "    If (feature 5 <= 2.5)\n",
            "     Predict: 0.0\n",
            "    Else (feature 5 > 2.5)\n",
            "     Predict: 1.0\n",
            "  Else (feature 1 > 2.5)\n",
            "   If (feature 5 <= 3.5)\n",
            "    If (feature 0 <= 6.5)\n",
            "     If (feature 3 <= 2.5)\n",
            "      Predict: 0.0\n",
            "     Else (feature 3 > 2.5)\n",
            "      If (feature 2 <= 2.5)\n",
            "       Predict: 0.0\n",
            "      Else (feature 2 > 2.5)\n",
            "       Predict: 1.0\n",
            "    Else (feature 0 > 6.5)\n",
            "     If (feature 2 <= 3.5)\n",
            "      Predict: 0.0\n",
            "     Else (feature 2 > 3.5)\n",
            "      Predict: 1.0\n",
            "   Else (feature 5 > 3.5)\n",
            "    If (feature 5 <= 4.5)\n",
            "     Predict: 1.0\n",
            "    Else (feature 5 > 4.5)\n",
            "     If (feature 1 <= 3.5)\n",
            "      If (feature 0 <= 1.5)\n",
            "       Predict: 0.0\n",
            "      Else (feature 0 > 1.5)\n",
            "       Predict: 1.0\n",
            "     Else (feature 1 > 3.5)\n",
            "      Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrDE6Mo8jnWs"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}